# @package _group_
scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  mode: min
  patience: 5
  min_lr: 0.000001
  verbose: True
interval: epoch
frequency: 1
monitor: val/loss
